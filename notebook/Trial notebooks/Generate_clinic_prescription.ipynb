{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotidabass/NLP-Projects/blob/main/How_to_Run_DeepSeek_Locally.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvmoBrghcxNl",
        "outputId": "4e03b7dc-3e2c-4e3a-89f2-70046c964425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Janus'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 121 (delta 51), reused 36 (delta 36), pack-reused 47 (from 2)\u001b[K\n",
            "Receiving objects: 100% (121/121), 7.19 MiB | 13.29 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/deepseek-ai/Janus.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9FxKIchYc5MP",
        "outputId": "daede0d8-81c5-4bc2-a0b1-4a88c39f62b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Janus\n",
            "Obtaining file:///content/Janus\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers>=4.38.2 in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (4.47.1)\n",
            "Requirement already satisfied: timm>=0.9.16 in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (1.0.14)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (1.2.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (0.2.0)\n",
            "Collecting attrdict (from janus==1.0.0)\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (0.8.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.16->janus==1.0.0) (0.20.1+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.16->janus==1.0.0) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.16->janus==1.0.0) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.16->janus==1.0.0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.1->janus==1.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.1->janus==1.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.1->janus==1.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.1->janus==1.0.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.1->janus==1.0.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.1->janus==1.0.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.1->janus==1.0.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.1->janus==1.0.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.1->janus==1.0.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.1->janus==1.0.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.1->janus==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (0.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->janus==1.0.0) (5.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from attrdict->janus==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->janus==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.38.2->janus==1.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.38.2->janus==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.38.2->janus==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.38.2->janus==1.0.0) (2024.12.14)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm>=0.9.16->janus==1.0.0) (11.1.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: janus\n",
            "  Building editable for janus (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for janus: filename=janus-1.0.0-0.editable-py3-none-any.whl size=15915 sha256=65993b5dd09918cf7ec7b549aa5de9a67e28918205d12d75b74d80f00e784803\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bjo3auid/wheels/04/ee/d6/76a460ef4080a263aa86cc3fdbb1c5bb29f559fbd8155d1c83\n",
            "Successfully built janus\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, attrdict, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, janus\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed attrdict-2.0.1 janus-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.5.1+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187815463 sha256=d944fc7d2f962bce83fc4708c2fc0c21eaf8255962a0b350ae919362a51b7ef2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.4.post1\n"
          ]
        }
      ],
      "source": [
        "%cd Janus\n",
        "!pip install -e .\n",
        "!pip install flash-attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "afDsLdMpc-TG",
        "outputId": "cfa8fed5-bfe1-4841-d980-a576201b38df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some kwargs in processor config are unused and will not have any effect: mask_prompt, ignore_id, num_image_tokens, sft_format, add_special_token, image_tag. \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM\n",
        "from janus.models import MultiModalityCausalLM, VLChatProcessor\n",
        "from janus.utils.io import load_pil_images\n",
        "\n",
        "# Define model path\n",
        "model_path = \"deepseek-ai/Janus-Pro-1B\"\n",
        "\n",
        "# Load processor and tokenizer\n",
        "vl_chat_processor = VLChatProcessor.from_pretrained(model_path)\n",
        "tokenizer = vl_chat_processor.tokenizer\n",
        "\n",
        "# Load model with remote code enabled\n",
        "vl_gpt = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
        "\n",
        "# Move model to GPU\n",
        "vl_gpt = vl_gpt.to(torch.bfloat16).cuda().eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_9VYiIRdC7p"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def get_company_name(image_path):\n",
        "  image_path = image_path\n",
        "  question = \"\"\"Guess the name of the clinic given the logo of the image\n",
        "                The output should only contain the name and no need anything extra\n",
        "                The output should have only company name without any extra characters or thoughts from assistant\n",
        "                Enclose the clinic name in double quotes\"\"\"\n",
        "\n",
        "  conversation = [\n",
        "      {\"role\": \"<|User|>\", \"content\": f\"<image_placeholder>\\n{question}\", \"images\": [image_path]},\n",
        "      {\"role\": \"<|Assistant|>\", \"content\": \"\"}\n",
        "  ]\n",
        "  # Load image\n",
        "  pil_images = load_pil_images(conversation)\n",
        "\n",
        "  # Prepare inputs for the model\n",
        "  prepare_inputs = vl_chat_processor(conversations=conversation, images=pil_images, force_batchify=True).to(vl_gpt.device)\n",
        "  inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
        "\n",
        "  # Generate response\n",
        "  outputs = vl_gpt.language_model.generate(\n",
        "      inputs_embeds=inputs_embeds,\n",
        "      attention_mask=prepare_inputs.attention_mask,\n",
        "      pad_token_id=tokenizer.eos_token_id,\n",
        "      bos_token_id=tokenizer.bos_token_id,\n",
        "      eos_token_id=tokenizer.eos_token_id,\n",
        "      max_new_tokens=512,\n",
        "      do_sample=False,\n",
        "      use_cache=True,\n",
        "  )\n",
        "\n",
        "  # Decode and print response\n",
        "  answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
        "  try:\n",
        "    result = re.findall(r'\"(.*?)\"', answer)\n",
        "    return result[0]\n",
        "  except:\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TIutMnjkuHY",
        "outputId": "150f1115-14cf-4dbb-d202-2ed1e66fa1be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (35.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.11/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from faker) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.4->faker) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install faker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLfIpcPfksW9"
      },
      "outputs": [],
      "source": [
        "from faker import Faker\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRsnQqUw0SuP"
      },
      "source": [
        "# Medical Bill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFWJKp_8dMxF"
      },
      "outputs": [],
      "source": [
        "def populate_records():\n",
        "    faker_object = Faker()\n",
        "    # Generate values for the placeholders\n",
        "    patient_name = faker_object.name()\n",
        "    date_of_visit = faker_object.date()\n",
        "    doctor_name = \"Dr.\"+faker_object.name()\n",
        "    insurance_provider = faker_object.company()\n",
        "    description = 'General consulation'\n",
        "\n",
        "    # Generate granular details (medicines/services)\n",
        "    granular_data = []\n",
        "    items = ['Paracetamol','Azithromycine','Novamax']\n",
        "    quantities = [str(random.randint(2,10)),\n",
        "                  str(random.randint(2,10)),\n",
        "                  str(random.randint(2,10))]\n",
        "    rates = [str(random.randint(8,30)),\n",
        "             str(random.randint(5,30)),\n",
        "             str(random.randint(7,30))]\n",
        "    for i in range(3):  # Generate 3 items\n",
        "        item = items[i]\n",
        "        quantity = quantities[i]\n",
        "        rate = rates[i]\n",
        "        total = float(quantity) * float(rate.replace('$', ''))  # Calculate total\n",
        "        granular_data.append({\n",
        "            'Item': item,\n",
        "            'Quantity': quantity,\n",
        "            'Rate': f\"${rate}\",\n",
        "            'Total': f\"${total:.2f}\"\n",
        "        })\n",
        "\n",
        "    # Calculate the overall total amount\n",
        "    total_amount = sum(float(item['Total'].replace('$', '')) for item in granular_data)\n",
        "    return patient_name, date_of_visit, doctor_name, insurance_provider, \\\n",
        "            description, granular_data, total_amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pBhJOxpKrE_L",
        "outputId": "5b54efcc-984e-44dd-aea1-fa337ac39ac2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Generated_Medical_Bill'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "drive_link = '/content/drive/MyDrive/omdena_legal'\n",
        "import os\n",
        "random.choice(os.listdir(drive_link))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "isxs1SftxsUH",
        "outputId": "68a80086-e59f-4edc-ff99-90a7d050752e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'733-570-0937x341'"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L88TV_z9iJG0"
      },
      "outputs": [],
      "source": [
        "from docx import Document\n",
        "import os\n",
        "import random\n",
        "from docx.shared import Inches\n",
        "from docx.shared import Pt\n",
        "from docx.oxml.ns import qn\n",
        "from docx.oxml import OxmlElement\n",
        "\n",
        "def document_template(num_docs):\n",
        "    faker_object = Faker()\n",
        "    # Create a new Word document\n",
        "    for i in range(num_docs):\n",
        "      doc = Document()\n",
        "      folder_choice = random.choice(os.listdir(f\"{drive_link}/Medical\"))\n",
        "      logo_choice = random.choice(os.listdir(f\"{drive_link}/Medical/{folder_choice}\"))\n",
        "      logo_path = f\"{drive_link}/Medical/{folder_choice}/{logo_choice}\"\n",
        "      doc.add_picture(logo_path, width=Inches(1.5))  # Adjust width as needed\n",
        "      doc.add_paragraph('\\n')  # Add space after the logo\n",
        "\n",
        "      # Add a header with clinic/hospital name\n",
        "      company_name = get_company_name(logo_path)\n",
        "      doc.add_heading(company_name, 0)\n",
        "      faker_object = Faker()\n",
        "      doc.add_paragraph(faker_object.address())\n",
        "      doc.add_paragraph(f'Phone: {faker_object.phone_number()} | Email: info@{company_name.replace(\" \", \"\")}.com')\n",
        "\n",
        "      # Add a title for the bill\n",
        "      doc.add_heading('Medical Bill', level=1)\n",
        "\n",
        "      # Add patient and billing details in a table\n",
        "      table = doc.add_table(rows=6, cols=2)\n",
        "      table.style = 'Table Grid'\n",
        "\n",
        "      # Fill the table with placeholders\n",
        "      rows = table.rows\n",
        "      rows[0].cells[0].text = 'Patient Name:'\n",
        "      rows[0].cells[1].text = '[Patient Name]'\n",
        "      rows[1].cells[0].text = 'Date of Visit:'\n",
        "      rows[1].cells[1].text = '[Date of Visit]'\n",
        "      rows[2].cells[0].text = 'Doctor Name:'\n",
        "      rows[2].cells[1].text = '[Doctor Name]'\n",
        "      rows[3].cells[0].text = 'Insurance Provider:'\n",
        "      rows[3].cells[1].text = '[Insurance Provider]'\n",
        "      rows[4].cells[0].text = 'Total Amount:'\n",
        "      rows[4].cells[1].text = '[Total Amount]'\n",
        "      rows[5].cells[0].text = 'Description of Services:'\n",
        "      rows[5].cells[1].text = '[Description]'\n",
        "\n",
        "      # Add a table for granular details (medicines, services, etc.)\n",
        "      doc.add_paragraph('\\nItemized Bill:')\n",
        "      granular_table = doc.add_table(rows=1, cols=4)\n",
        "      granular_table.style = 'Table Grid'\n",
        "\n",
        "      # Add headers for the granular table\n",
        "      header_row = granular_table.rows[0].cells\n",
        "      header_row[0].text = 'Item'\n",
        "      header_row[1].text = 'Quantity'\n",
        "      header_row[2].text = 'Rate (USD)'\n",
        "      header_row[3].text = 'Total (USD)'\n",
        "\n",
        "      # Add placeholders for granular details\n",
        "      for _ in range(3):  # Add 3 rows for medicines/services\n",
        "          row = granular_table.add_row().cells\n",
        "          row[0].text = '[Item]'\n",
        "          row[1].text = '[Quantity]'\n",
        "          row[2].text = '[Rate]'\n",
        "          row[3].text = '[Total]'\n",
        "\n",
        "      # Add additional paragraphs\n",
        "      doc.add_paragraph('\\nPayment Terms:')\n",
        "      doc.add_paragraph('Payment is due within 30 days of the invoice date. Late payments may incur a fee of 1.5% per month.')\n",
        "\n",
        "      doc.add_paragraph('\\nDisclaimer:')\n",
        "      doc.add_paragraph('This bill is generated based on the services provided. Please contact us for any discrepancies.')\n",
        "\n",
        "      doc.add_paragraph('\\nFollow-Up Instructions:')\n",
        "      doc.add_paragraph('Please schedule a follow-up appointment if required. Contact our reception for availability.')\n",
        "\n",
        "      # Add a signature section\n",
        "      doc.add_paragraph('\\n\\nAuthorized Signature:')\n",
        "\n",
        "      folder_choice = random.choice(os.listdir(f\"{drive_link}/signature/Dataset_Signature_Final/Dataset\"))\n",
        "      subfolder = random.choice(['forge','real'])\n",
        "      sign_choice = random.choice(os.listdir(f\"{drive_link}/signature/Dataset_Signature_Final/Dataset/{folder_choice}/{subfolder}\"))\n",
        "      signature_path = f\"{drive_link}/signature/Dataset_Signature_Final/Dataset/{folder_choice}/{subfolder}/{sign_choice}\"\n",
        "      doc.add_picture(signature_path, width=Inches(1.5))  # Adjust width as needed\n",
        "      doctor = \"Dr.\"+faker_object.name()\n",
        "      doc.add_paragraph(f'{doctor}\\nChief Medical Officer\\n{company_name}')\n",
        "      #doc.save(f'medical_bill_template_{i}.docx')\n",
        "      data = populate_records()\n",
        "      populate_to_document(data,doc, i)\n",
        "\n",
        "def populate_to_document(data, document, nth_doc):\n",
        "    # Load the template document\n",
        "    doc = document\n",
        "\n",
        "    # Replace placeholders with generated values\n",
        "    for paragraph in doc.paragraphs:\n",
        "        if '[Patient Name]' in paragraph.text:\n",
        "            paragraph.text = paragraph.text.replace('[Patient Name]', data[0])\n",
        "        if '[Date of Visit]' in paragraph.text:\n",
        "            paragraph.text = paragraph.text.replace('[Date of Visit]', data[1])\n",
        "        if '[Doctor Name]' in paragraph.text:\n",
        "            paragraph.text = paragraph.text.replace('[Doctor Name]', data[2])\n",
        "        if '[Insurance Provider]' in paragraph.text:\n",
        "            paragraph.text = paragraph.text.replace('[Insurance Provider]', data[3])\n",
        "        if '[Total Amount]' in paragraph.text:\n",
        "            paragraph.text = paragraph.text.replace('[Total Amount]', f\"${data[6]:.2f}\")\n",
        "        if '[Description]' in paragraph.text:\n",
        "            paragraph.text = paragraph.text.replace('[Description]', data[4])\n",
        "\n",
        "    # Replace placeholders in tables\n",
        "    for table in doc.tables:\n",
        "        for row in table.rows:\n",
        "            for cell in row.cells:\n",
        "                if '[Patient Name]' in cell.text:\n",
        "                    cell.text = cell.text.replace('[Patient Name]', data[0])\n",
        "                if '[Date of Visit]' in cell.text:\n",
        "                    cell.text = cell.text.replace('[Date of Visit]', data[1])\n",
        "                if '[Doctor Name]' in cell.text:\n",
        "                    cell.text = cell.text.replace('[Doctor Name]', data[2])\n",
        "                if '[Insurance Provider]' in cell.text:\n",
        "                    cell.text = cell.text.replace('[Insurance Provider]', data[3])\n",
        "                if '[Total Amount]' in cell.text:\n",
        "                    cell.text = cell.text.replace('[Total Amount]', f\"${data[6]:.2f}\")\n",
        "                if '[Description]' in cell.text:\n",
        "                    cell.text = cell.text.replace('[Description]', data[4])\n",
        "\n",
        "    # Replace granular table placeholders with generated data\n",
        "    granular_table = doc.tables[1]  # Second table in the document\n",
        "    for i, item in enumerate(data[5]):\n",
        "        row = granular_table.rows[i + 1].cells  # Skip header row\n",
        "        row[0].text = item['Item']\n",
        "        row[1].text = item['Quantity']\n",
        "        row[2].text = item['Rate']\n",
        "        row[3].text = item['Total']\n",
        "\n",
        "    # Save the populated document\n",
        "    doc.save(rf'/content/drive/MyDrive/omdena_legal/Generated_Medical_Bill/generated_medical_bill_{nth_doc}.docx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzDHe4NVCF7S"
      },
      "outputs": [],
      "source": [
        "document_template(num_docs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0B30PM30ChX"
      },
      "source": [
        "# GDPR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHoQ_swW0BzI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr_yjxtOvGaO"
      },
      "outputs": [],
      "source": [
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "\n",
        "# Function to create GDPR policy document\n",
        "def create_gdpr_policy(company_name, company_address, contact_email, logo_path, signature_path, output_file):\n",
        "    # Create a new Word document\n",
        "    doc = Document()\n",
        "\n",
        "    # Add a title\n",
        "    doc.add_heading(f'GDPR Policy Document for {company_name}', level=1)\n",
        "\n",
        "    # Add the company logo\n",
        "    if logo_path:\n",
        "        doc.add_picture(logo_path, width=Inches(2.0))\n",
        "        doc.add_paragraph(' ')  # Add some space after the logo\n",
        "\n",
        "    # Section 1: Introduction\n",
        "    doc.add_heading('1. Introduction', level=2)\n",
        "    doc.add_paragraph(\n",
        "        f\"This document outlines the General Data Protection Regulation (GDPR) policy of {company_name}. \"\n",
        "        \"It explains how we collect, process, and protect personal data in compliance with GDPR.\"\n",
        "    )\n",
        "\n",
        "    # Section 2: Scope\n",
        "    doc.add_heading('2. Scope', level=2)\n",
        "    doc.add_paragraph(\n",
        "        \"This policy applies to all employees, contractors, and third-party vendors who handle personal data \"\n",
        "        \"on behalf of the company.\"\n",
        "    )\n",
        "\n",
        "    # Section 3: Personal Data Collected\n",
        "    doc.add_heading('3. Personal Data Collected', level=2)\n",
        "    doc.add_paragraph(\n",
        "        \"We may collect the following types of personal data (PII):\"\n",
        "    )\n",
        "    pii_list = [\n",
        "        \"Full name\",\n",
        "        \"Email address\",\n",
        "        \"Phone number\",\n",
        "        \"Home address\",\n",
        "        \"IP address\",\n",
        "        \"Bank account details (if applicable)\"\n",
        "    ]\n",
        "    for item in pii_list:\n",
        "        doc.add_paragraph(f\"- {item}\", style='List Bullet')\n",
        "\n",
        "    # Section 4: Data Processing\n",
        "    doc.add_heading('4. Data Processing', level=2)\n",
        "    doc.add_paragraph(\n",
        "        \"Personal data is processed for the following purposes:\"\n",
        "    )\n",
        "    processing_purposes = [\n",
        "        \"To fulfill contractual obligations\",\n",
        "        \"To comply with legal requirements\",\n",
        "        \"To improve our services\",\n",
        "        \"For marketing purposes (with consent)\"\n",
        "    ]\n",
        "    for purpose in processing_purposes:\n",
        "        doc.add_paragraph(f\"- {purpose}\", style='List Bullet')\n",
        "\n",
        "    # Section 5: Data Security\n",
        "    doc.add_heading('5. Data Security', level=2)\n",
        "    doc.add_paragraph(\n",
        "        \"We implement appropriate technical and organizational measures to ensure the security of personal data. \"\n",
        "        \"This includes encryption, access controls, and regular audits.\"\n",
        "    )\n",
        "\n",
        "    # Section 6: Data Subject Rights\n",
        "    doc.add_heading('6. Data Subject Rights', level=2)\n",
        "    doc.add_paragraph(\n",
        "        \"Data subjects have the following rights under GDPR:\"\n",
        "    )\n",
        "    subject_rights = [\n",
        "        \"Right to access personal data\",\n",
        "        \"Right to rectification\",\n",
        "        \"Right to erasure (right to be forgotten)\",\n",
        "        \"Right to restrict processing\",\n",
        "        \"Right to data portability\",\n",
        "        \"Right to object\"\n",
        "    ]\n",
        "    for right in subject_rights:\n",
        "        doc.add_paragraph(f\"- {right}\", style='List Bullet')\n",
        "\n",
        "    # Section 7: Contact Information\n",
        "    doc.add_heading('7. Contact Information', level=2)\n",
        "    doc.add_paragraph(\n",
        "        f\"For any questions or concerns regarding this policy, please contact us at:\\n\\n\"\n",
        "        f\"Company Name: {company_name}\\n\"\n",
        "        f\"Address: {company_address}\\n\"\n",
        "        f\"Email: {contact_email}\"\n",
        "    )\n",
        "\n",
        "    # Add a signature section\n",
        "    doc.add_heading('Signature', level=2)\n",
        "    doc.add_paragraph(\"I hereby confirm that I have read and understood the GDPR policy of the company.\")\n",
        "    if signature_path:\n",
        "        doc.add_picture(signature_path, width=Inches(1.5))\n",
        "    else:\n",
        "        doc.add_paragraph(\"[Signature Placeholder]\")\n",
        "\n",
        "    doc.save(rf'/content/drive/MyDrive/omdena_legal/GDPR/{output_file}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNhKE8PVz5-x"
      },
      "outputs": [],
      "source": [
        "faker_object = Faker()\n",
        "for i in range(50):\n",
        "  folder_choice = random.choice(os.listdir(f\"{drive_link}/Medical\"))\n",
        "  logo_choice = random.choice(os.listdir(f\"{drive_link}/Medical/{folder_choice}\"))\n",
        "  logo_path = f\"{drive_link}/Medical/{folder_choice}/{logo_choice}\"\n",
        "  company_name = get_company_name(logo_path)\n",
        "  company_address = faker_object.address()\n",
        "  contact_email = f'info@{company_name.replace(\" \", \"\")}.com'\n",
        "  folder_choice = random.choice(os.listdir(f\"{drive_link}/signature/Dataset_Signature_Final/Dataset\"))\n",
        "  subfolder = random.choice(['forge','real'])\n",
        "  sign_choice = random.choice(os.listdir(f\"{drive_link}/signature/Dataset_Signature_Final/Dataset/{folder_choice}/{subfolder}\"))\n",
        "  signature_path = f\"{drive_link}/signature/Dataset_Signature_Final/Dataset/{folder_choice}/{subfolder}/{sign_choice}\"\n",
        "  create_gdpr_policy(company_name, company_address,\n",
        "                     contact_email, logo_path,\n",
        "                     signature_path, f\"GDPR_generated_{i}.docx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDmvcJ1S1ljP"
      },
      "source": [
        "# Docs to pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Raghu Studies\\omdena\\CameroonFranceChapter_LegalComplianceAssistant\\.src_omdena_legal\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from docx2pdf import convert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "with open(r\"D:\\Raghu Studies\\omdena\\CameroonFranceChapter_LegalComplianceAssistant\\data\\legaldoc_all_ann.json\") as f:\n",
        "  annotations = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
            "\n",
            "\u001b[A\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
            "\n",
            "\u001b[A\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
            "\n",
            "\u001b[A\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
            "\n",
            "\u001b[A\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
            "\n",
            "\u001b[A\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
            "\n",
            "\u001b[A\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
            "\n",
            "\u001b[A\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
            "\n",
            "\u001b[A\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
            "\n",
            "\u001b[A\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n"
          ]
        }
      ],
      "source": [
        "for docname in annotations:\n",
        "  doc_name_pdf = docname['documentName']\n",
        "  doc_name = doc_name_pdf.split(\".\")[0]+\".docx\"\n",
        "  convert(rf\"D:\\Raghu Studies\\omdena\\CameroonFranceChapter_LegalComplianceAssistant\\data\\divorce\\{doc_name}\", doc_name_pdf )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pdf2image\n",
            "  Obtaining dependency information for pdf2image from https://files.pythonhosted.org/packages/62/33/61766ae033518957f877ab246f87ca30a85b778ebaad65b7f74fa7e52988/pdf2image-1.17.0-py3-none-any.whl.metadata\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in d:\\raghu studies\\omdena\\cameroonfrancechapter_legalcomplianceassistant\\.src_omdena_legal\\lib\\site-packages (from pdf2image) (11.1.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 25.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Detailed_Divorce_Agreement_0.pdf',\n",
              " 'Detailed_Divorce_Agreement_1.pdf',\n",
              " 'Detailed_Divorce_Agreement_10.pdf',\n",
              " 'Detailed_Divorce_Agreement_2.pdf',\n",
              " 'Detailed_Divorce_Agreement_3.pdf',\n",
              " 'Detailed_Divorce_Agreement_4.pdf',\n",
              " 'Detailed_Divorce_Agreement_5.pdf',\n",
              " 'Detailed_Divorce_Agreement_7.pdf',\n",
              " 'Detailed_Divorce_Agreement_8.pdf',\n",
              " 'Detailed_Divorce_Agreement_9.pdf']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "pdf_list = os.listdir(r'D:\\Raghu Studies\\omdena\\CameroonFranceChapter_LegalComplianceAssistant\\notebook')\n",
        "pdf_list = [pdfs for pdfs in pdf_list if(\".pdf\" in pdfs)]\n",
        "pdf_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "\n",
        "for pdfs in pdf_list:\n",
        "    file_name_image = pdfs.split(\".\")[0]\n",
        "    pages = convert_from_path(pdfs, 500, poppler_path=r'C:\\Program Files\\poppler-24.08.0\\Library\\bin')\n",
        "    \n",
        "    for count, page in enumerate(pages):\n",
        "        resized_page = page.resize((762, 1000)) # to match the resolution what is present in funsd dataset\n",
        "        \n",
        "        resized_page.save(rf'D:\\Raghu Studies\\omdena\\CameroonFranceChapter_LegalComplianceAssistant\\notebook\\images\\{file_name_image}_pg{count}.jpg', 'JPEG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from pdf2image import convert_from_path\n",
        "for pdfs in pdf_list:\n",
        "    file_name_image = pdfs.split(\".\")[0]\n",
        "    pages = convert_from_path(pdfs, 500, poppler_path=r'C:\\Program Files\\poppler-24.08.0\\Library\\bin')\n",
        "    for count, page in enumerate(pages):\n",
        "        page.save(rf'D:\\Raghu Studies\\omdena\\CameroonFranceChapter_LegalComplianceAssistant\\notebook\\images\\{file_name_image}_pg{count}.jpg', 'JPEG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Detailed_Divorce_Agreement_3.pdf'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#inception\n",
        "# admin\n",
        "# admin1234\n",
        "# java -jar inception-app-webapp-35.2-standalone.jar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convert Docx to PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = r\"D:\\Raghu Studies\\omdena\\CameroonFranceChapter_LegalComplianceAssistant\\data\\GDPR\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files = os.listdir(PATH)\n",
        "import os\n",
        "import win32com.client\n",
        "files = os.listdir(PATH)\n",
        "\n",
        "def convert_docx_to_pdf(input_path, output_path=None):\n",
        "    print(input_path)\n",
        "    word = win32com.client.Dispatch(\"Word.Application\")\n",
        "    word.Visible = False  # Run Word in the background\n",
        "\n",
        "    try:\n",
        "        doc = word.Documents.Open(os.path.abspath(input_path))\n",
        "\n",
        "        doc.SaveAs(os.path.abspath(output_path), FileFormat=17)  # 17 is the PDF format\n",
        "        doc.Close()\n",
        "        print(f\"Converted {input_path} to {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    finally:\n",
        "        word.Quit()\n",
        "\n",
        "\n",
        "for in_file in files:\n",
        "    doc_path = PATH + rf\"\\{in_file}\"\n",
        "    os.makedirs(PATH + rf\"\\pdf\", exist_ok=True)\n",
        "    output_path = PATH + rf\"\\pdf\\{in_file.split('.docx')[0]}.pdf\"\n",
        "    convert_docx_to_pdf(doc_path, output_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convert PDF to images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pdf2image import convert_from_path\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_pdf_to_images(path):\n",
        "    path_files = os.listdir(path)[:10] # take only 10 files\n",
        "    output_path = r\"D:/Raghu Studies/omdena/CameroonFranceChapter_LegalComplianceAssistant/data/yolo_training_images\"\n",
        "    pdf_list = [path + rf\"/{files}\" for files in path_files]\n",
        "    for pdfs in pdf_list:\n",
        "        file_name_image = pdfs.split(r\"/\")[-1].split(\".\")[0]\n",
        "        pages = convert_from_path(pdfs, 500)\n",
        "\n",
        "        for count, page in enumerate(pages):\n",
        "\n",
        "            page.save(rf'{output_path}/{file_name_image}_pg{count}.jpg', 'JPEG')\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [01:33<00:00, 15.63s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "paths = [r'D:/Raghu Studies/omdena/CameroonFranceChapter_LegalComplianceAssistant/data/Dissolution_Petitions/pdf',\n",
        "         r'D:/Raghu Studies/omdena/CameroonFranceChapter_LegalComplianceAssistant/data/Financial_bills',\n",
        "         r'D:/Raghu Studies/omdena/CameroonFranceChapter_LegalComplianceAssistant/data/Generated_Medical_Bill/pdf',\n",
        "         r'D:/Raghu Studies/omdena/CameroonFranceChapter_LegalComplianceAssistant/data/Lease_Agreements/pdf',\n",
        "         r'D:/Raghu Studies/omdena/CameroonFranceChapter_LegalComplianceAssistant/data/NDA_Documents/pdf',\n",
        "         r'D:/Raghu Studies/omdena/CameroonFranceChapter_LegalComplianceAssistant/data/Partnership_Agreements/pdf']\n",
        "\n",
        "for path in tqdm(paths):\n",
        "    convert_pdf_to_images(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".src_omdena_legal",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
